Perfect ğŸš€ â€” letâ€™s dive into the next part:

# ğŸŒ **Kubernetes Service Discovery in Prometheus**

---

## ğŸ§­ 1ï¸âƒ£ Why We Need Service Discovery

In a normal (non-Kubernetes) setup, you manually list all targets in `prometheus.yml`:

```yaml
static_configs:
  - targets: ["10.0.1.2:9100", "10.0.1.3:9100"]
```

But in Kubernetes, pods and services are **dynamic** â€” they start, die, or move every minute.
So, manual configs quickly become outdated.

ğŸ‘‰ **Prometheus solves this** using **service discovery** (SD): it automatically detects new targets via the Kubernetes API.

---

## âš™ï¸ 2ï¸âƒ£ How It Works

Prometheus queries the Kubernetes API to discover objects based on a **role**.
Each role tells Prometheus what kind of object to scrape:

| Role        | Discovers         | Typical Metrics            |
| ----------- | ----------------- | -------------------------- |
| `node`      | Worker nodes      | Node Exporter, Kubelet     |
| `pod`       | Individual pods   | Application exporters      |
| `service`   | Cluster services  | Internal app metrics       |
| `endpoints` | Service endpoints | Load-balanced exporters    |
| `ingress`   | Ingress resources | HTTP metrics from gateways |

Prometheus periodically re-syncs (default: every 30 seconds) so that the target list is always up-to-date.

---

## ğŸ§© 3ï¸âƒ£ Example: Service Discovery for Pods

```yaml
scrape_configs:
  - job_name: "pods"
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        replacement: $1
```

ğŸ§  **Explanation:**

* Prometheus asks the K8s API for all pods.
* It filters only those annotated with
  `prometheus.io/scrape: "true"`.
* It reads the port from the annotation
  `prometheus.io/port: "9100"`.

So, you enable scraping by adding this annotation to your pod or deployment:

```yaml
metadata:
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9100"
```

---

## ğŸ§© 4ï¸âƒ£ Example: Service Discovery for Services

```yaml
scrape_configs:
  - job_name: "services"
    kubernetes_sd_configs:
      - role: service
```

This discovers all Kubernetes Services, but usually youâ€™ll pair it with `endpoints`:

```yaml
scrape_configs:
  - job_name: "endpoints"
    kubernetes_sd_configs:
      - role: endpoints
```

Each Serviceâ€™s `spec.selector` determines which pods are behind it, so Prometheus automatically finds all matching pods.

---

## ğŸ” 5ï¸âƒ£ Service Discovery for Kubelet Metrics

```yaml
scrape_configs:
  - job_name: "kubelet"
    kubernetes_sd_configs:
      - role: node
    scheme: https
    tls_config:
      insecure_skip_verify: true
    relabel_configs:
      - source_labels: [__address__]
        regex: (.*):10250
        target_label: instance
        replacement: $1
```

âœ… Discovers all nodes and scrapes the Kubeletâ€™s `/metrics` endpoint securely over HTTPS.

---

## ğŸ“œ 6ï¸âƒ£ Common Relabeling Rules

| Purpose                  | Example Rule                                                 | What It Does             |
| ------------------------ | ------------------------------------------------------------ | ------------------------ |
| Keep only annotated pods | `__meta_kubernetes_pod_annotation_prometheus_io_scrape=true` | Filters targets          |
| Rename labels            | `target_label: job`                                          | Normalizes label names   |
| Drop internal pods       | `regex: "kube-system/.*"` â†’ `action: drop`                   | Removes noise            |
| Add cluster info         | `target_label: cluster`                                      | Adds environment context |

---

## ğŸ” 7ï¸âƒ£ Visualizing the Discovery Process

```mermaid
flowchart LR
A[Prometheus] -->|Queries| B[Kubernetes API]
B -->|Returns Pod/Service Metadata| A
A -->|Scrapes| C[Exporter Endpoints]
C --> D[(Prometheus TSDB)]
```

ğŸ§© Every 30 seconds:

* Prometheus asks API Server â†’ â€œWhoâ€™s alive?â€
* Gets pods, endpoints, and services
* Applies relabeling â†’ final scrape list
* Scrapes metrics â†’ stores in TSDB

---

## ğŸ§° 8ï¸âƒ£ Best Practices

| Best Practice                          | Why It Matters                                           |
| -------------------------------------- | -------------------------------------------------------- |
| ğŸŸ¢ Use annotations (`prometheus.io/*`) | Easy, lightweight control                                |
| ğŸŸ¢ Use ServiceMonitors (if Operator)   | More maintainable than raw YAML                          |
| ğŸŸ¢ Limit scrape scope                  | Avoid collecting thousands of noisy metrics              |
| ğŸŸ¢ Use namespaces selectively          | Focus on `production`, skip `kube-system` if unnecessary |
| ğŸŸ¢ Monitor Prometheus target status    | Detect discovery or auth issues fast                     |

---

## ğŸ’¡ TL;DR

> Kubernetes Service Discovery = dynamic target discovery through the API.
> Prometheus watches nodes, pods, and services, applies relabeling, and scrapes exporters automatically â€” no static IPs ever again ğŸ¯.

---

Would you like the **next topic** to be:
1ï¸âƒ£ â€œInstalling Prometheus in Kubernetes (Helm + Operator setup)â€
or
2ï¸âƒ£ â€œMonitoring Kubernetes system components (API server, Controller Manager, Scheduler, etc.)â€?
