Perfect üòé ‚Äî now we move to the **Worker Node & Pod Level Monitoring in Kubernetes** ‚Äî this is where Prometheus shines by giving you visibility into **resource usage, pod health, and node performance**.

---

# üß© Monitoring Nodes & Pods in Kubernetes with Prometheus

> ‚ÄúIf the Control Plane is the *brain*, then Nodes and Pods are the *muscles* of Kubernetes.‚Äù ‚Äî Let‚Äôs learn how to keep those muscles healthy üí™

---

## üß≠ 1Ô∏è‚É£ Overview: Why Monitor Nodes & Pods?

Once your **control plane** is stable, you need to ensure:

* Worker nodes have enough CPU, memory, and disk.
* Pods are scheduled and performing as expected.
* Bottlenecks (like container throttling or node pressure) are detected early.

Prometheus provides this visibility by scraping **three key metric sources:**

| Source            | Exposed By                   | Port  | Purpose                                         |
| ----------------- | ---------------------------- | ----- | ----------------------------------------------- |
| **Node Exporter** | DaemonSet on each node       | 9100  | Host-level metrics (CPU, memory, disk, network) |
| **Kubelet**       | Kubelet service on each node | 10250 | Pod and container runtime metrics               |
| **cAdvisor**      | Built-in inside Kubelet      | 10250 | Container-level resource usage                  |

---

## ‚öôÔ∏è 2Ô∏è‚É£ Architecture Diagram

```mermaid
flowchart TD
subgraph Worker Node 1
A[Node Exporter<br>Port 9100]:::node
B[Kubelet<br>Port 10250]:::kube
B --> C[cAdvisor (built-in)]
end

subgraph Worker Node 2
D[Node Exporter]:::node
E[Kubelet]
E --> F[cAdvisor]
end

P[Prometheus<br>(Kube-Prometheus Stack)]:::prom
P --> A
P --> B
P --> D
P --> E

classDef prom fill:#f2c94c,stroke:#222,color:#000;
classDef node fill:#27ae60,stroke:#222,color:#fff;
classDef kube fill:#2d9cdb,stroke:#222,color:#fff;
```

üß© Prometheus scrapes:

* **Node Exporter** for OS-level metrics
* **Kubelet (cAdvisor)** for container-level metrics
* **Kubernetes API** for pod labels and metadata

---

## üîß 3Ô∏è‚É£ Installing Node Exporter as DaemonSet

Node Exporter is deployed on *every node* to expose hardware & OS metrics.

### Example DaemonSet YAML

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: monitoring
  labels:
    k8s-app: node-exporter
spec:
  selector:
    matchLabels:
      k8s-app: node-exporter
  template:
    metadata:
      labels:
        k8s-app: node-exporter
    spec:
      hostPID: true
      hostNetwork: true
      containers:
        - name: node-exporter
          image: prom/node-exporter:v1.6.1
          ports:
            - containerPort: 9100
              hostPort: 9100
              name: metrics
          volumeMounts:
            - name: rootfs
              mountPath: /host
              readOnly: true
      volumes:
        - name: rootfs
          hostPath:
            path: /
```

After deployment:

```bash
kubectl apply -f node-exporter-daemonset.yaml
kubectl get pods -n monitoring -o wide
```

---

## üß† 4Ô∏è‚É£ Scraping Node Exporter Metrics

Add a `ServiceMonitor` (if using Prometheus Operator):

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: node-exporter
  namespace: monitoring
spec:
  selector:
    matchLabels:
      k8s-app: node-exporter
  namespaceSelector:
    matchNames:
      - monitoring
  endpoints:
    - port: metrics
      interval: 30s
```

‚úÖ You‚Äôll now collect metrics like:

* `node_cpu_seconds_total`
* `node_memory_MemAvailable_bytes`
* `node_disk_io_time_seconds_total`
* `node_network_receive_bytes_total`

---

## üß© 5Ô∏è‚É£ Kubelet & cAdvisor Metrics

The **Kubelet** process on each node also exposes metrics that include:

* Pod resource usage (CPU/memory)
* Container restarts
* Filesystem usage inside pods

### Kubelet Metrics Endpoints

| Type     | Endpoint                                | Description                       |
| -------- | --------------------------------------- | --------------------------------- |
| General  | `https://<node>:10250/metrics`          | Node + container metrics          |
| Resource | `https://<node>:10250/metrics/resource` | Detailed CPU/memory per container |
| cAdvisor | `https://<node>:10250/metrics/cadvisor` | Container-level details           |

‚úÖ These are automatically discovered by **kube-prometheus-stack** if installed via Helm.

If manually configuring:

```yaml
scrape_configs:
  - job_name: 'kubelet'
    scheme: https
    kubernetes_sd_configs:
      - role: node
    tls_config:
      insecure_skip_verify: true
    relabel_configs:
      - source_labels: [__metrics_path__]
        target_label: __metrics_path__
        replacement: /metrics
```

---

## üìä 6Ô∏è‚É£ Common Metrics Examples

| Category         | Metric Name                                 | Description                   |
| ---------------- | ------------------------------------------- | ----------------------------- |
| **Node Health**  | `node_load1`, `node_filesystem_avail_bytes` | CPU load, disk space          |
| **Pod Resource** | `container_cpu_usage_seconds_total`         | CPU time used by container    |
| **Memory**       | `container_memory_usage_bytes`              | Memory consumed               |
| **Filesystem**   | `container_fs_usage_bytes`                  | Storage used inside container |
| **Networking**   | `container_network_transmit_bytes_total`    | Bytes sent by pod             |

---

## üìà 7Ô∏è‚É£ Grafana Dashboards

| Dashboard ID | Title                      | Purpose                                 |
| ------------ | -------------------------- | --------------------------------------- |
| **1860**     | Node Exporter Full         | Node CPU, disk, and network usage       |
| **315**      | cAdvisor / Container Stats | Per-container usage                     |
| **6417**     | Kubelet Overview           | Pod resource summaries                  |
| **8588**     | Kubernetes / Nodes         | Combined view of node + pod performance |

Example screenshot (you‚Äôll see nodes listed, resource graphs, and container usage per pod).

---

## üß∞ 8Ô∏è‚É£ Best Practices

| Tip                               | Why                                           |
| --------------------------------- | --------------------------------------------- |
| üß± Run Node Exporter as DaemonSet | Ensures coverage on all nodes                 |
| üîí Protect metrics endpoints      | Use NetworkPolicies or mTLS                   |
| ‚öôÔ∏è Use recording rules            | Aggregate per-node and per-pod metrics        |
| üö¶ Set alerts                     | CPU > 90%, memory > 95%, or disk near full    |
| üîÅ Correlate with logs            | Combine with Loki or FluentBit for root cause |

---

## üß† 9Ô∏è‚É£ Summary

| Layer               | Source             | Metrics Scope                  |
| ------------------- | ------------------ | ------------------------------ |
| Node                | Node Exporter      | Host-level CPU, disk, network  |
| Kubelet             | Kubelet / cAdvisor | Container-level performance    |
| Prometheus Operator | ServiceMonitor     | Automated discovery & scraping |
| Grafana             | Dashboards         | Visualization and alerts       |

---

## üí° TL;DR

> In Kubernetes, monitor **nodes** with Node Exporter and **pods/containers** with Kubelet + cAdvisor.
> Combined, they provide complete visibility from physical resources to running workloads.
> Prometheus Operator automates discovery, Grafana visualizes, and you ‚Äî the observability hero ‚Äî sleep peacefully üò¥.

---

Would you like me to continue next with **Kubernetes Service Discovery in Prometheus** (how Prometheus automatically finds new pods, services, and nodes without manual config)?
