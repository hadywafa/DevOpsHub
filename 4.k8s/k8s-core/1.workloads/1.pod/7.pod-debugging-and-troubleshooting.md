# ğŸ§¯ Kubernetes Pods 106 â€” **Debugging, Troubleshooting & Recovery Techniques**

> ğŸ¯ **Goal:** Learn how to investigate, debug, and recover broken Pods like a real cluster admin â€” using logs, events, ephemeral containers, and practical commands.

---

## ğŸ§  **The Pod Lifecycle** (Quick Recap)

Pods go through these **phases**:

```ini
Pending â†’ Running â†’ Succeeded / Failed / Unknown
```

Each container in a Pod has its own **state**:

- **Waiting**: Container is preparing (pulling image, waiting for resources)
- **Running**: Actively running
- **Terminated**: Completed or failed
- **CrashLoopBackOff**: Container keeps restarting

---

## ğŸªœ **Step-by-Step Troubleshooting** Workflow

When a Pod misbehaves, always follow this sequence:

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

```mermaid
flowchart TD
A[Check Pod Status] --> B[Inspect Events]
B --> C[Check Logs]
C --> D[Inspect Container Details]
D --> E[Exec into Container / Debug]
E --> F[Inspect Node / Scheduler Issues]
```

</div>

Letâ€™s break these steps down ğŸ‘‡

---

## ğŸ“Œ **Step 1 â€” Check Pod Status**

```bash
kubectl get pods -A -o wide
```

Focus on:

- **STATUS** â†’ Pending, CrashLoopBackOff, Error
- **READY** â†’ e.g., `1/2` means 1 container is running, 1 failed
- **RESTARTS** â†’ High restart count = unstable container

---

### Example Output

```ini
NAME           READY   STATUS             RESTARTS   AGE
nginx-demo     0/1     CrashLoopBackOff   4          2m
```

Next â†’ describe it ğŸ‘‡

---

## ğŸ“Œ **Step 2 â€” Describe the Pod** (See Events)

```bash
kubectl describe pod nginx-demo
```

Scroll to bottom for **Events**:

```ini
Events:
  Type     Reason     Message
  ----     ------     -------
  Normal   Scheduled  Successfully assigned default/nginx-demo to node-1
  Normal   Pulling    Pulling image "nginx"
  Warning  Failed     Error: CrashLoopBackOff
```

### Common Event Reasons:

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

| Reason                 | Description                              |
| ---------------------- | ---------------------------------------- |
| `ImagePullBackOff`     | Image not found or authentication failed |
| `CrashLoopBackOff`     | App crashed repeatedly                   |
| `ErrImagePull`         | Bad image name or registry               |
| `OOMKilled`            | Memory limit exceeded                    |
| `CreateContainerError` | Bad volume or env setup                  |

</div>

---

## ğŸ“Œ **Step 3 â€” Inspect Logs**

```bash
kubectl logs nginx-demo
```

If multi-container Pod:

```bash
kubectl logs nginx-demo -c <container-name>
```

View previous crash logs:

```bash
kubectl logs nginx-demo -p
```

---

### Example:

```ini
Error: Port 8080 already in use
```

â†’ App conflict or duplicate process.

---

## ğŸ“Œ **Step 4 â€” Get Inside the Pod** (Exec Shell)

```bash
kubectl exec -it nginx-demo -- /bin/bash
# or for alpine/busybox
kubectl exec -it nginx-demo -- sh
```

âœ… Check running processes, environment, and configs:

```bash
ps aux
env
ls /etc/config
```

---

### Quick Fix Example:

```ini
kubectl exec -it nginx-demo -- sed -i 's/8080/80/g' /etc/nginx/conf.d/default.conf
```

---

## ğŸ“Œ **Step 5 â€” Pod Not Starting** (Image or Config Issues)

### ğŸ” Check Image Pull

```bash
kubectl describe pod <pod> | grep -A3 "Failed"
```

Errors like:

```ini
Failed to pull image "myapp:v2": image not found
```

âœ… Fix by updating image:

```bash
kubectl set image pod/myapp myapp=repo/myapp:latest
```

---

### ğŸ” Check Environment Variables

```bash
kubectl exec -it <pod> -- printenv
```

Or YAML:

```bash
kubectl get pod <pod> -o yaml | grep -A5 env:
```

---

### ğŸ” Check Volume Mounts

```bash
kubectl describe pod <pod> | grep -A3 Mounts
```

If mount path missing â†’ verify PVC:

```bash
kubectl get pvc
kubectl describe pvc <name>
```

---

## ğŸ“Œ **Step 6 â€” Troubleshooting Stuck or Pending Pods**

```bash
kubectl describe pod <pod> | grep -A5 Events
```

Typical errors:

- `0/3 nodes available: 3 Insufficient memory`
- `node(s) didn't match node selector`
- `node(s) had taints that the pod didn't tolerate`

**âœ… Fix by adjusting:**

- resource requests
- node selectors
- tolerations

---

## ğŸ“Œ **Debugging CrashLoopBackOff**

CrashLoopBackOff = Container starts, crashes, restarts repeatedly.

### Analyze:

```bash
kubectl logs <pod> -p
```

If app bug â†’ fix container or startup script.
If config issue â†’ verify readiness/liveness probes.

---

### Check restart count

```bash
kubectl get pods
```

If increasing rapidly â†’ CrashLoopBackOff confirmed.

---

### Restart behavior:

Pods controlled by Deployments auto-recreate â€” deleting wonâ€™t help.
Better approach:

```bash
kubectl rollout restart deployment <name>
```

---

## ğŸ“Œ **Step 7 â€” Use `kubectl debug` (Ephemeral Containers)**

Ephemeral containers allow debugging **without modifying the Pod**.
Perfect for troubleshooting production Pods.

### Example:

```bash
kubectl debug -it <pod> --image=busybox --target=<container-name>
```

âœ… This launches a **temporary shell container** inside the Pod network namespace.

Inside:

```bash
ps aux
netstat -tulpn
```

Exit â†’ ephemeral container auto-deletes.

---

## ğŸ“Œ **Step 8 â€” Network Troubleshooting**

If Pod canâ€™t reach another service:

```bash
kubectl exec -it <pod> -- curl <svc-name>:<port>
```

If fails:
1ï¸âƒ£ Check Service and Endpoints:

```bash
kubectl get svc <svc-name>
kubectl get endpoints <svc-name>
```

2ï¸âƒ£ If Endpoints = `<none>` â†’ backing Pods not Ready.
Check selectors:

```bash
kubectl get pods -l <label>
```

3ï¸âƒ£ Test DNS:

```bash
kubectl exec -it <pod> -- nslookup <svc-name>
```

---

## ğŸ“Œ **Step 9 â€” Pod Stuck in Terminating State**

Common causes:

- Finalizers not cleared
- Mounted PVC busy
- Network connection hanging

Force delete:

```bash
kubectl delete pod <pod> --grace-period=0 --force
```

---

## ğŸ“Œ **Step 10 â€” Pod Evicted by Node Pressure**

Check status:

```bash
kubectl get pods --field-selector=status.phase=Failed
kubectl describe pod <name>
```

Look for:

```ini
The node was low on resource: memory.
```

âœ… Fix: increase node memory or use higher QoS class.  
ğŸ§© Evicted pods are **not restarted** â€” controller (e.g. Deployment) must recreate.

---

## ğŸ“Œ **Step 11 â€” Init Containers Debugging**

Init containers run **before** app containers to prepare environment.
If one fails â†’ main container never starts.

View init container logs:

```bash
kubectl logs <pod> -c <init-container-name>
```

Check status:

```bash
kubectl get pod <pod> -o jsonpath='{.status.initContainerStatuses[*].state}'
```

---

## ğŸ“Œ **Step 12 â€” Liveness & Readiness Probe Failures**

Liveness probes control **restart** behavior.  
Readiness probes control **traffic acceptance**.

Check failures:

```bash
kubectl describe pod <pod> | grep -A5 "Liveness probe failed"
```

Example YAML:

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 10
```

âœ… If probe misconfigured â†’ app keeps restarting unnecessarily.

---

## ğŸ§© 16. Step 13 â€” Resource Problems (OOMKilled, Throttling)

```bash
kubectl describe pod <pod> | grep -i "OOMKilled"
```

Memory limit exceeded â†’ container killed.

For CPU:

```bash
kubectl top pod
```

Throttling visible in metrics.

Fix:

- Adjust resource limits
- Use QoS class `Guaranteed` for critical pods

---

## ğŸ“Œ **Step 14 â€” Node-Level Problems**

If all pods pending or failing:

```bash
kubectl get nodes
kubectl describe node <node>
```

Look for:

- DiskPressure
- MemoryPressure
- NetworkUnavailable

Fix by:

```bash
kubectl cordon <node>
kubectl drain <node> --ignore-daemonsets
```

Then investigate system logs.

---

## ğŸ§° **Advanced Admin Commands Summary**

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

| Task                  | Command                                             |     |
| --------------------- | --------------------------------------------------- | --- |
| Get logs              | `kubectl logs <pod>`                                |     |
| Get previous logs     | `kubectl logs -p <pod>`                             |     |
| Describe pod          | `kubectl describe pod <pod>`                        |     |
| Exec into container   | `kubectl exec -it <pod> -- bash`                    |     |
| Attach to running pod | `kubectl attach <pod>`                              |     |
| Debug ephemeral       | `kubectl debug -it <pod> --image=busybox`           |     |
| Delete forcefully     | `kubectl delete pod <pod> --force --grace-period=0` |     |
| Check probes          | `kubectl get pod <pod> -o yaml | grep -A5 probe`    |

</div>

---

## ğŸ’­ **Common Real-World Scenarios**

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

| Symptom               | Root Cause                  | Fix                           |
| --------------------- | --------------------------- | ----------------------------- |
| `CrashLoopBackOff`    | App crash / probe failure   | Check logs, fix probe         |
| `ImagePullBackOff`    | Bad image name / auth issue | Fix image reference or secret |
| `OOMKilled`           | Memory limit exceeded       | Increase limits or optimize   |
| `PodPending`          | Scheduler constraints       | Fix selectors or taints       |
| `No route to host`    | CNI issue                   | Restart network plugin        |
| `Terminating forever` | Finalizer lock              | Force delete pod              |
| `Evicted`             | Node pressure               | Scale nodes or raise limits   |

</div>

---

## âœğŸ» **Hands-On Admin Lab**

1ï¸âƒ£ Simulate crash:

```bash
kubectl run crashpod --image=busybox --restart=Never -- sh -c "exit 1"
```

Check:

```bash
kubectl get pods
kubectl describe pod crashpod
```

2ï¸âƒ£ Debug DNS:

```bash
kubectl run dns-test --image=busybox:1.28 -it -- nslookup kubernetes.default
```

3ï¸âƒ£ Add ephemeral debug:

```bash
kubectl debug -it crashpod --image=busybox --target=crashpod
```

4ï¸âƒ£ Fix deployment crash:

```bash
kubectl rollout restart deployment <name>
kubectl rollout status deployment <name>
```

---

## ğŸ” **Recovery Best Practices**

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

| Area                          | Action                                        |
| ----------------------------- | --------------------------------------------- |
| **Always check Events first** | They tell the full story                      |
| **Avoid blind deletes**       | Use `rollout restart` instead                 |
| **Use probes carefully**      | Donâ€™t make them too strict                    |
| **Monitor restarts**          | `kubectl get pods` frequently                 |
| **Keep a debug image handy**  | e.g. `nicolaka/netshoot`, `busybox`, `alpine` |

</div>

---

## âœ… **Summary**

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

| Concept           | You Can Now...                    |
| ----------------- | --------------------------------- |
| Pod Lifecycle     | Interpret every status            |
| Logs & Events     | Identify root causes quickly      |
| Ephemeral Debug   | Enter any Pod for inspection      |
| Resource Failures | Detect OOM, CPU throttling        |
| Node Issues       | Drain, isolate, and recover nodes |

</div>

---

## ğŸ§­ Next Major Section

ğŸ‰ Youâ€™ve completed **Pod Administration (1â€“6)**
Next, we move to the **Workload Level** â€” starting with:

### ğŸš€ **Deployments 101 â€” Creating, Scaling & Managing Deployments**

Itâ€™ll cover:

- ReplicaSets management
- Rollouts, revisions, rollbacks
- Canary updates & blue/green patterns
