# ⚙️ Kubernetes Pods 104 — **Resource Requests**, **Limits** & **QoS Classes**

> 💡 Goal: Become fluent in how Kubernetes handles CPU, memory, and Quality of Service (QoS).  
> You’ll master how to **set**, **inspect**, and **troubleshoot** pod resource controls like a real admin.

---

## 🎯 **Objectives**

- Understand **requests** (reservation) and **limits** (enforcement)
- Learn **CPU/memory units** and scheduling impact
- Manage **QoS classes**: Guaranteed, Burstable, BestEffort
- Troubleshoot out-of-resource events (OOMKilled, throttling)

---

## 📖 **Why Resource Management Matters**

Kubernetes schedules pods based on **available node resources**.  
If you don’t set requests/limits:

- Some pods **hog** CPU or RAM 🐷
- Some pods get **killed** by the kernel OOMKiller 💀

✅ Setting resource configs ensures:

- **Fairness**
- **Predictable scheduling**
- **Stable cluster performance**

---

## 📐 **CPU & Memory Units**

### 🧮 **CPU**

- 1 CPU = 1 vCPU or 1 core
- Fractional units supported (e.g. `500m` = 0.5 core)

### 💾 **Memory**

- Expressed in bytes (e.g. `Mi`, `Gi`)

  - `Mi` = mebibytes (1024²)
  - `Gi` = gibibytes (1024³)

Example:

```yaml
resources:
  requests:
    cpu: "500m"
    memory: "256Mi"
  limits:
    cpu: "1"
    memory: "512Mi"
```

---

## ⚔️ **Resource Requests vs Limits**

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

| Concept      | Meaning                                   | Effect                                     |
| ------------ | ----------------------------------------- | ------------------------------------------ |
| **Requests** | Minimum resources guaranteed to container | Scheduler uses this to find a node         |
| **Limits**   | Maximum resources container can use       | Kubelet enforces this (throttles or kills) |

</div>

---

### 🧠 **Scheduler Logic**

When placing a pod:

- Adds up all container **requests**
- Finds node where `available ≥ requests`
- Schedules pod there
  Even if pod later consumes **less**, node remains **reserved**.

---

## 📃 **Container-Level Example**

In Kubernetes, resources.requests and resources.limits are defined per container, not per pod.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-demo
spec:
  containers:
    - name: cpu-mem-demo
      image: nginx
      resources:
        requests:
          memory: "128Mi"
          cpu: "250m"
        limits:
          memory: "256Mi"
          cpu: "500m"
```

---

### 🧪 Verify Requests & Limits

```bash
kubectl get pod resource-demo -o custom-columns=NAME:.metadata.name,REQUESTS:.spec.containers[*].resources.requests,MEM:.spec.containers[*].resources.limits
```

Or describe:

```bash
kubectl describe pod resource-demo
```

---

## 🧠 **CPU Behavior**

- **Exceeding limit** → throttled (not killed)
- **Below request** → allowed, no penalty
- **No limit** → can burst freely until node is saturated

Check throttling via metrics:

```bash
kubectl top pod
```

---

## 💾 **Memory Behavior**

- **Exceeding limit** → container killed (`OOMKilled`)
- **No limit** → may kill neighbors if node runs out of memory
- **Request only** → scheduler respects reservation, but may still kill if limit missing

Inspect OOM:

```bash
kubectl describe pod <pod> | grep -i "OOMKilled"
```

---

## ⚖️ **QoS (Quality of Service) Classes**

Determined automatically based on requests/limits of all containers in pod.

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

| Class          | Rules                                    | Behavior                              |
| -------------- | ---------------------------------------- | ------------------------------------- |
| **Guaranteed** | Requests = Limits for **all containers** | Highest priority; killed last         |
| **Burstable**  | Requests < Limits (or mixed)             | Middle priority                       |
| **BestEffort** | No requests or limits                    | Killed first during resource pressure |

</div>

---

### 📝 Example 1: Guaranteed Pod

```yaml
resources:
  requests:
    cpu: "500m"
    memory: "256Mi"
  limits:
    cpu: "500m"
    memory: "256Mi"
```

✅ Requests = Limits → **Guaranteed**

---

### 📝 Example 2: Burstable Pod

```yaml
resources:
  requests:
    cpu: "250m"
    memory: "128Mi"
  limits:
    cpu: "500m"
    memory: "256Mi"
```

✅ Requests < Limits → **Burstable**

---

### 📝 Example 3: BestEffort Pod

```yaml
# no resources defined
```

✅ No requests/limits → **BestEffort**

---

### 🧪 Check QoS Class

```bash
kubectl get pod <pod> -o jsonpath='{.status.qosClass}'
```

---

## ⚙️ **Node Resource Accounting**

View total capacity:

```bash
kubectl describe node <nodename> | grep -A5 "Capacity"
```

List pod usage:

```bash
kubectl top pod
```

List node usage:

```bash
kubectl top node
```

---

## 🔴 **Troubleshooting Resource Issues**

### ⏳ Pod Pending (Unschedulable)

Cause: requests exceed available node resources
Check:

```bash
kubectl describe pod <pod>
```

Look for:

```ini
0/3 nodes are available: 3 Insufficient memory.
```

Fix: lower requests or add larger nodes.

---

### 💀 Pod OOMKilled

Cause: memory limit exceeded
Fix:

- Increase memory limit
- Optimize app memory usage

---

### 🚫 CPU Throttling

Cause: exceeded CPU limit
Fix:

- Raise limit or remove it for critical pods

---

### 👟 Node Eviction

When node under pressure:

- Evicts **BestEffort** first, then **Burstable**, then **Guaranteed**
- Marked as `Evicted` in pod status

Check:

```bash
kubectl get pods --field-selector=status.phase=Failed
```

---

## 🧮 **Resource Quotas** (Namespace-Level Control)

Prevent users from consuming too many cluster resources.

### Create quota

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: dev-quota
  namespace: dev
spec:
  hard:
    pods: "10"
    requests.cpu: "2"
    limits.memory: "4Gi"
```

Apply:

```bash
kubectl apply -f quota.yaml
```

View:

```bash
kubectl describe quota -n dev
```

---

### Combine with LimitRange (Default Resource Policies)

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: container-limits
  namespace: dev
spec:
  limits:
    - default:
        cpu: 500m
        memory: 512Mi
      defaultRequest:
        cpu: 250m
        memory: 256Mi
      type: Container
```

Apply defaults for containers missing resource specs.
Check:

```bash
kubectl describe limitrange -n dev
```

---

## 🧰 **Handy Admin Commands**

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

| Task                | Command                                                   |
| ------------------- | --------------------------------------------------------- |
| Show pod resources  | `kubectl top pod`                                         |
| Show node resources | `kubectl top node`                                        |
| Describe QoS        | `kubectl get pod <name> -o jsonpath='{.status.qosClass}'` |
| Check quota usage   | `kubectl describe quota`                                  |
| Apply defaults      | `kubectl apply -f limitrange.yaml`                        |
| Check pending pods  | `kubectl get pods \| grep Pending`                        |

</div>

---

## ✅ **Admin Insights**

- Always set **requests** for scheduler stability
- Use **limits** carefully — too low → throttling, too high → wasted resources
- Guarantee QoS for critical workloads (e.g., DBs)
- Use **LimitRange** and **ResourceQuota** in shared clusters
- Monitor continuously via **metrics-server** and **kubectl top**

---

## 🧪 **Practical Hands-On**

1️⃣ Create a pod with requests/limits:

```bash
kubectl run demo --image=nginx --requests='cpu=200m,memory=128Mi' --limits='cpu=500m,memory=256Mi'
```

2️⃣ View usage:

```bash
kubectl top pod demo
```

3️⃣ Get QoS:

```bash
kubectl get pod demo -o jsonpath='{.status.qosClass}'
```

4️⃣ Simulate OOM:

```bash
kubectl exec -it demo -- sh -c "dd if=/dev/zero of=/dev/null bs=1M count=500"
```

5️⃣ Check pod events:

```bash
kubectl describe pod demo
```
