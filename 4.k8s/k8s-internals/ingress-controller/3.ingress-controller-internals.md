# üåê **Kubernetes Ingress Controller Internals**

_(from YAML ‚Üí Pod ‚Üí Routing ‚Üí NGINX Config ‚Üí Network Flow)!_

---

## üî¥ **The Problem Before Ingress**

Imagine you deployed 3 apps inside your cluster:

- `frontend-service` (port 80)
- `api-service` (port 8080)
- `admin-service` (port 9000)

Without Ingress, you had two bad choices:

- ‚ùå Expose each service with a **NodePort** (e.g. `:30001`, `:30002`, `:30003`)
- ‚ùå Or use a **LoadBalancer** per service (expensive in cloud environments)

That meant multiple public IPs or weird URLs like:

```ini
http://nodeip:30001/
http://nodeip:30002/
```

üëé Not scalable. Not pretty. Not cheap.

---

## üü¢ **Enter the Hero: Ingress**

**Ingress** solves this by being a single, smart entry point.
You define **routing rules** in one YAML file (Ingress Resource), and an **Ingress Controller** applies those rules dynamically.

**In short:**

> One IP ‚Üí Many internal Services
> One Ingress Controller ‚Üí Many routing rules

---

## üèóÔ∏è **Ingress Architecture Overview**

<div align="center" style="background-color: #232b2dff; border-radius: 10px; border: 2px solid">

```mermaid
graph TD
    A([üë§ User])
    B[(üåç DNS)]
    C@{ shape: hex, label: "‚òÅÔ∏è LoadBalancer / NodeIP" }
    D@{ shape: hex, label: "üö¶ Ingress Service (NodePort)" }
    E@{ shape: processes, label: "‚öôÔ∏è Ingress Controller Pod (NGINX)" }

    X{{"üö¶ Backend Service A (ClusterIP)"}}
    Y{{"üö¶ Backend Service B (ClusterIP)"}}
    Z{{"üö¶ Backend Service C (ClusterIP)"}}
    X1@{ shape: processes, label: "‚öôÔ∏è App A Pods" }
    Y1@{ shape: processes, label: "‚öôÔ∏è App B Pods" }
    Z1@{ shape: processes, label: "‚öôÔ∏è App C Pods" }

    A e1@--> B
    B e2@--> C
    C e3@--> D
    D e4@--> E
    E e5@-->|Reverse Proxy| X
    E e6@-->|Reverse Proxy| Y
    E e7@-->|Reverse Proxy| Z
    X e8@--> X1
    Y e9@--> Y1
    Z e10@--> Z1

    classDef animate stroke-dasharray: 9,5,stroke-dashoffset: 900,animation: dash 25s linear infinite;
    class e1,e2,e3,e4,e5,e6,e7,e8,e9,e10 animate
```

</div>

---

## üß© **Core Components Explained**

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

| Component                 | Type                              | Role                                                                                |
| ------------------------- | --------------------------------- | ----------------------------------------------------------------------------------- |
| **Ingress Resource**      | Custom API Object                 | Declares desired routing (host/path ‚Üí service:port).                                |
| **IngressClass Resource** | API Object                        | Declares _which controller_ will handle that Ingress.                               |
| **Ingress Controller**    | Deployment (Pods)                 | Runs the control loop that watches Ingresses and updates proxy config (like NGINX). |
| **Ingress Service**       | Service (NodePort / LoadBalancer) | Exposes the controller Pods to external world.                                      |
| **Reverse Proxy Process** | Inside Pod                        | Applies routing rules in real time (usually NGINX, HAProxy, or Envoy).              |

</div>

---

## ü™ú **How It Works ‚Äì Step-by-Step**

Let‚Äôs break the full flow in _chronological order_, from YAML ‚Üí Pod ‚Üí Traffic.

---

### üßæ Step 1: You Define the Ingress Resource

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp
spec:
  ingressClassName: nginx
  rules:
    - host: example.com
      http:
        paths:
          - path: /api
            pathType: Prefix
            backend:
              service:
                name: api-service
                port:
                  number: 8080
          - path: /admin
            pathType: Prefix
            backend:
              service:
                name: admin-service
                port:
                  number: 9000
```

You‚Äôre basically saying:

> ‚ÄúHey Kubernetes, when traffic comes for `example.com/api` or `/admin`, send it to those internal services.‚Äù

This YAML only defines **desired state** ‚Äî no routing happens yet.

---

### üßæ Step 2: You Have an IngressClass

```yaml
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  name: nginx
spec:
  controller: k8s.io/ingress-nginx
```

This defines _which controller implementation_ handles your Ingress.
If multiple controllers exist (say, NGINX and Traefik), the `controller:` string helps each one filter Ingresses it owns.

> Think of this as ‚Äúthe department responsible for your traffic rules‚Äù.

---

### üöÄ Step 3: The Ingress Controller Deployment (the brains)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: ingress-nginx
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ingress-nginx
    spec:
      serviceAccountName: ingress-nginx
      containers:
        - name: controller
          image: registry.k8s.io/ingress-nginx/controller:v1.13.3
          args:
            - /nginx-ingress-controller
            - --controller-class=k8s.io/ingress-nginx
            - --ingress-class=nginx
            - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
```

This runs a **controller binary** (like `nginx-ingress-controller`) inside a Pod.

---

## ‚öôÔ∏è **What Happens Internally Inside the Controller Pod**

Let‚Äôs peek inside the controller process.

### üîÅ a. Watch Loop (the ‚ÄúController‚Äù logic)

It continuously **watches**:

- Ingress Resources
- Services
- Endpoints
- Secrets (for TLS)

and keeps an internal cache.

When it sees a new Ingress or Service, it:

1. Parses routing rules (host/path/backend)
2. Resolves backend endpoints (Pod IPs)
3. Generates a fresh NGINX config file
4. Atomically replaces `/etc/nginx/nginx.conf`
5. Gracefully reloads NGINX process

All automated ‚Äî no human touches it.

---

### üß© b. Informer Pattern (real magic)

The controller uses **Informers** from `client-go` to watch Kubernetes API events.

```go
ingressInformer.AddEventHandler(cache.ResourceEventHandlerFuncs{
  AddFunc:    handleIngress,
  UpdateFunc: handleIngressUpdate,
  DeleteFunc: handleIngressDelete,
})
```

Whenever you `kubectl apply -f ingress.yaml`, it triggers a reconcile loop.

---

### üß† c. Reconcile Loop (think ‚Äúdiff engine‚Äù)

The reconcile logic:

1. Compare desired state (from YAML) vs current state (NGINX config)
2. If differences ‚Üí regenerate `nginx.conf`
3. Call `nginx -s reload`

---

### üß∞ d. Template Rendering

The controller uses a **Go template** to render backend routes:

Example:

```nginx
upstream api-service_8080 {
    server 10.244.0.10:8080;
    server 10.244.0.11:8080;
}
server {
    server_name example.com;
    location /api {
        proxy_pass http://api-service_8080;
    }
}
```

So, your YAML literally becomes part of NGINX configuration dynamically.

---

### ‚ö° e. Graceful Reload

Instead of killing the process, it sends:

```bash
nginx -s reload
```

This reloads configuration **without dropping connections** ‚Äî crucial for production.

---

## üåç **How External Traffic Actually Enters**

1. The controller is exposed by a **Service of type NodePort or LoadBalancer**:

   ```bash
   kubectl get svc -n ingress-nginx
   ```

   Output:

   ```ini
   NAME                       TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)
   ingress-nginx-controller    LoadBalancer   10.0.0.12      35.201.22.5   80:30080/TCP,443:30443/TCP
   ```

2. External requests go to the **LoadBalancer IP** (or Node IP:NodePort in Kind).

3. The Service forwards traffic to the controller Pods.

4. NGINX inside those Pods proxies requests internally to your services.

---

## üîç **DNS and Domain Wiring**

- You map your domain (e.g. `example.com`) ‚Üí to the Ingress LB IP:

  ```ini
  example.com ‚Üí 35.201.22.5
  ```

- When you hit `https://example.com/api`, it reaches the NGINX pod.
- The pod matches your host/path and routes to the correct backend Service.

---

## üîè **TLS Termination**

When you add TLS:

```yaml
tls:
  - hosts:
      - example.com
    secretName: example-tls
```

The controller fetches `example-tls` secret, extracts cert/key, and configures NGINX `ssl_certificate` blocks automatically.

So HTTPS termination happens **inside the Ingress pod** ‚Äî your services still receive plain HTTP traffic.

---

## üñºÔ∏è **End-to-End Traffic Flow**

<div align="center" style="background-color: #232b2dff; border-radius: 10px; border: 2px solid">

```mermaid
sequenceDiagram
  participant User
  participant IngressService as Ingress Service (NodePort/LB)
  participant ControllerPod as NGINX Controller Pod
  participant BackendSvc as Backend Service
  participant Pod as Target Pod

  User->>IngressService: HTTP GET /api
  IngressService->>ControllerPod: forwards via NodePort/LB
  ControllerPod->>ControllerPod: NGINX matches Host + Path
  ControllerPod->>BackendSvc: proxy_pass http://api-service
  BackendSvc->>Pod: forwards to Pod IP via kube-proxy / CNI
  Pod-->>User: returns response via same reverse path
```

</div>

---

## üß™ **How to Inspect in Kind**

To _see it working_:

```bash
kubectl get ingress
kubectl get svc -n ingress-nginx
kubectl exec -it deploy/ingress-nginx-controller -n ingress-nginx -- cat /etc/nginx/nginx.conf
kubectl logs -n ingress-nginx deploy/ingress-nginx-controller -f
```

---

## üìã **Summary Table**

<div align="center" style="background-color: #141a19ff;color: #a8a5a5ff; border-radius: 10px; border: 2px solid">

| Layer   | Component              | Type                  | Description                      |
| ------- | ---------------------- | --------------------- | -------------------------------- |
| User    | Browser / Client       | External              | Sends HTTP/HTTPS requests        |
| Node    | Ingress Service        | Service (LB/NodePort) | Exposes controller to outside    |
| Pod     | Ingress Controller Pod | Deployment Pod        | Runs NGINX + Controller logic    |
| Config  | Ingress Resource       | API Object            | Desired routing rules            |
| Config  | IngressClass           | API Object            | Controller ownership binding     |
| Runtime | NGINX Process          | Binary inside Pod     | Reverse proxy performing routing |
| Runtime | kube-proxy + CNI       | Kernel / Plugin       | Handles backend pod traffic      |
| Backend | ClusterIP Service      | Service               | Routes to app Pods               |
| Backend | Pod                    | Workload              | Responds to user requests        |

</div>

---

## ü§î **Why It‚Äôs Not a Control Plane Controller?**

- It **uses** the Kubernetes API, but it‚Äôs **not** part of control plane.
- It‚Äôs an **add-on controller**, deployed as a regular Pod.
- The real Kubernetes control plane (kube-controller-manager) doesn‚Äôt manage HTTP routing.

So yes ‚Äî it‚Äôs a **custom controller**, but **not** a ‚ÄúControl Plane‚Äù one.

---

## üß† **Memorization Trick**

> üß© **Ingress Resource** = ‚ÄúTraffic Rule Book‚Äù  
> üß† **Ingress Controller** = ‚ÄúPolice that enforces rules‚Äù  
> üè¢ **IngressClass** = ‚ÄúDepartment that owns that rulebook‚Äù  
> üö™ **Ingress Pod (NGINX)** = ‚ÄúDoorman applying those rules live‚Äù

üí° Say this aloud 3 times:

> ‚ÄúIngress Resource defines it,  
> IngressClass assigns it,  
> Ingress Controller enforces it,  
> NGINX inside Pod executes it.‚Äù

Boom ‚Äî that‚Äôs all Ingress internals, end-to-end.
