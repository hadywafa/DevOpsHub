# ðŸ“¤ **Amazon S3 Multipart Uploads**

Amazon S3 **Multipart Uploads** allow you to upload large objects in **discrete parts**, independently and in **parallel** â€” improving reliability, speed, and flexibility.

<div align="center" style="padding: 0 20px;">
  <img src="images/s3-multi-upload.png" style="border-radius: 10px;" alt="s3-multi-upload">
</div>

---

## ðŸ” **What Is Multipart Upload?**

Instead of uploading a massive file in one go (which can fail midway), Multipart Upload breaks it into **smaller chunks** (parts), uploads them independently, then assembles them into a single object.

---

## ðŸ“ **Multipart Upload Limits**

| Requirement        | Value                                |
| ------------------ | ------------------------------------ |
| ðŸ“¦ Minimum size    | 5 MB per part (except the last part) |
| âš  Required for     | Objects **larger than 5 GB**         |
| ðŸ’¡ Recommended for | Objects **larger than 100 MB**       |
| ðŸ›‘ Max object size | 5 TB (combined size of all parts)    |
| ðŸ§© Max parts       | 10,000 parts per upload              |

---

## ðŸš€ **Why Use Multipart Uploads?**

### âœ… **Faster Uploads**

- Upload parts **in parallel** to maximize network throughput.

### ðŸ” **Retry Only What Fails**

- If part 7 fails, retry **only part 7**, not the whole object.

### â¸ï¸ **Pause and Resume Support**

- You can **pause** uploads and **resume** them later using the upload ID.

### ðŸ’¾ **Efficient for Spotty Connections**

- Great for unreliable networks, especially for mobile or remote uploads.

---

## ðŸ› ï¸ **How It Works: Step-by-Step**

```mermaid
sequenceDiagram
    participant Client as Your App (Uploader)
    participant S3 as Amazon S3

    Client->>S3: Initiate Multipart Upload
    S3-->>Client: Upload ID

    loop For each part
        Client->>S3: Upload Part (with Upload ID & Part Number)
        S3-->>Client: 200 OK + ETag
    end

    Client->>S3: Complete Multipart Upload (with all ETags)
    S3-->>Client: Final Object Created âœ…
```

---

## ðŸ§ª **Code Example: Multipart Upload (Boto3 Python)**

```python
import boto3
from boto3.s3.transfer import TransferConfig

s3 = boto3.client('s3')

# Optional: Fine-tune transfer config
config = TransferConfig(
    multipart_threshold=1024 * 25,  # 25MB threshold
    multipart_chunksize=1024 * 25, # 25MB chunks
    use_threads=True
)

# Upload file with multipart
s3.upload_file(
    Filename='large_file.zip',
    Bucket='my-bucket-name',
    Key='uploads/large_file.zip',
    Config=config
)
```

---

## ðŸ’¡ **Best Practices**

- ðŸ“ **Use multipart upload for files >100MB** to improve speed and reliability.
- ðŸ§µ **Enable multithreading** for parallel part uploads.
- ðŸ§  **Track Upload IDs** if you plan to pause/resume later.
- ðŸ§¹ **Abort incomplete uploads** to avoid storage waste (you can set lifecycle rules for this).

---

## ðŸ“Œ Summary Table

| Benefit                      | Description                            |
| ---------------------------- | -------------------------------------- |
| âš¡ Faster uploads            | Upload parts in parallel               |
| ðŸ’ª Resilient uploads         | Retry individual failed parts          |
| ðŸ§  Intelligent storage usage | Pause/resume and control uploads       |
| ðŸ§¹ Easy cleanup              | Abort unfinished uploads to free space |
| âœ… Required for >5GB uploads | Multipart required for any object >5GB |
