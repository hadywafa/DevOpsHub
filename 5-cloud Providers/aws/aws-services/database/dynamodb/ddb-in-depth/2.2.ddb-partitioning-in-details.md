# ğŸ¯ **How Does DynamoDB Define the Total Number of Partitions?**

DynamoDB determines the total number of **partitions** based on **table size** and **throughput capacity**.

## **1ï¸âƒ£ Partition Calculation Based on Storage**

Each partition in DynamoDB can store **up to 10GB** of data.  
ğŸ”¹ If you insert **50GB** of data, DynamoDB will create:
\[
50GB / 10GB = 5 \text{ partitions}
\]

- If the table grows beyond **10GB per partition**, DynamoDB **automatically splits partitions**.

## **2ï¸âƒ£ Partition Calculation Based on Throughput**

- Each partition can handle **up to 3,000 Read Capacity Units (RCUs)** and **1,000 Write Capacity Units (WCUs)**.
- If you provision **10,000 RCUs**, DynamoDB will **spread the load across multiple partitions** to avoid overloading a single one.

### ğŸ”¢ **Example: Calculating Partitions Based on Capacity**

| **Scenario**                 | **Partition Count** |
| ---------------------------- | ------------------- |
| **5GB table, 500 RCUs**      | 1 Partition         |
| **20GB table, 4,000 RCUs**   | 4 Partitions        |
| **100GB table, 10,000 RCUs** | 10+ Partitions      |

---

## ğŸ”¢ **How Does DynamoDB Find the Correct Partition?**

DynamoDB uses a **consistent hashing algorithm** to distribute data across partitions.

### **ğŸ“Œ Step 1: Hashing the Partition Key**

When you insert or query data, DynamoDB **hashes** the partition key using the **MurmurHash3** algorithm.

\[
\text{hash}(partition_key) \mod \text{total partitions} = \text{Partition Number}
\]

### **ğŸ“Œ Step 2: Mapping the Hash to a Partition**

Let's say we have **3 partitions** and we insert three users:

| **UserID** | **Hashed Value (Simulated)** | **Partition**                    |
| ---------- | ---------------------------- | -------------------------------- |
| `USR1001`  | 89347292                     | `89347292 % 3 = 2` (Partition 2) |
| `USR2002`  | 23984713                     | `23984713 % 3 = 1` (Partition 1) |
| `USR3003`  | 59012384                     | `59012384 % 3 = 0` (Partition 0) |

So:

- `USR1001` â†’ Partition **2**
- `USR2002` â†’ Partition **1**
- `USR3003` â†’ Partition **0**

---

### ğŸ“œ **Visualizing How Hashing Finds the Partition**

```mermaid
graph LR
    A[Client Request UserID ] -->|Hashing Function| B{MurmurHash3 UserId }
    B --> C[Modulo Operation: hash UserID % Total Partitions]
    C -->|Partition 0| P0[Partition 0]
    C -->|Partition 1| P1[Partition 1]
    C -->|Partition 2| P2[Partition 2]
```

- The **hash function** ensures even distribution.
- The **modulo operation** maps the hashed value to a **specific partition**.
- **If partitions increase**, DynamoDB automatically **recomputes the mappings** to balance data.

---

## ğŸš€ **What Happens When Partitions Increase?**

### **ğŸ›  Case 1: More Data is Added**

- If **a partition exceeds 10GB**, DynamoDB **splits it into two partitions**.
- The **hashing function adjusts** so that old and new partitions get a balanced share.

### **ğŸ›  Case 2: Read/Write Capacity Exceeds a Partition's Limit**

- If a partition is **handling too many requests**, DynamoDB **creates a new partition** and redistributes the workload.

---

## ğŸ **Key Takeaways**

âœ… **Total partitions** are based on **storage (10GB limit per partition) and throughput needs**.  
âœ… DynamoDB uses **MurmurHash3** to determine which partition holds the data.  
âœ… The **hash result modulo total partitions** ensures **even distribution**.  
âœ… DynamoDB **automatically resizes partitions** as the table grows.

---

ğŸ”¥ **Want to test this with real AWS CLI or SDK examples? Let me know!** ğŸš€
