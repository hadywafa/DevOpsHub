# 🚀 Getting Started with Amazon Managed Service for Apache Flink (MSF)

Amazon Managed Service for Apache Flink (MSF) is a **serverless** way to run **real-time streaming applications** built on Apache Flink—without worrying about infrastructure! Whether you're processing event data from Kafka or Kinesis, MSF lets you write in Java, Scala, Python, or SQL and deploy effortlessly.

---

## 🧠 What is Amazon MSF?

Amazon MSF is a fully managed Flink runtime on AWS. It enables:

- 🔄 **Stream Processing** in real time (sub-second latency!)
- 🔧 **Zero infrastructure management** – AWS handles the scaling, HA, and updates
- 🔗 **Deep integration with AWS services** – Kinesis, MSK, S3, Redshift, etc.
- 🔥 Ideal for streaming analytics, real-time dashboards, alerting, and ETL

---

## 🏗️ How MSF Works (Under the Hood)

```mermaid
flowchart TD
    A[Streaming Data Sources] -->|Kinesis / Kafka / S3| B[Amazon MSF (Flink App)]
    B --> C[Operators: Map, Filter, Join]
    C --> D[Sinks: S3 / Redshift / DynamoDB]
    D --> E[Consumers: BI tools, Dashboards, ML Models]
```

- **Sources**: MSF connects to streaming data using Flink connectors
- **Operators**: You write logic using Flink APIs
- **Sinks**: Data is delivered to destinations like S3, Redshift, or MSK

---

## 🛠️ Step-by-Step Setup

Let’s walk through creating and deploying your first MSF app using the official AWS [workshop](https://catalog.workshops.aws/managed-flink/en-US/flink-on-msf).

---

### 📋 Prerequisites

- ✅ AWS Account
- 💻 Java 11 SDK + Maven
- 🧰 AWS CLI installed and configured
- 💡 (Optional) IntelliJ IDEA or your favorite IDE

---

### 📦 1. Set Up Data Streams

Use AWS CLI to create input/output streams:

```bash
aws kinesis create-stream --stream-name ExampleInputStream --shard-count 1
aws kinesis create-stream --stream-name ExampleOutputStream --shard-count 1
```

---

### 🧾 2. Develop Your Flink Application

Clone the example repo:

```bash
git clone https://github.com/aws-samples/amazon-msf-udf-workshop.git
cd amazon-msf-udf-workshop
```

Build the app:

```bash
mvn clean package
```

Upload your `.jar` to S3:

```bash
aws s3 cp target/msf-demo-app.jar s3://your-flink-bucket/
```

---

### 🚀 3. Deploy MSF Application

From AWS Console:

- Go to **Amazon Managed Service for Apache Flink**
- Click **Create Application**
- Choose the `.jar` from your S3 bucket
- Set **Input = Kinesis Stream**, **Output = Kinesis Stream or S3**

💡 You can also enable **snapshot backups**, **metrics**, and **log streaming to CloudWatch**.

---

### ⚙️ Application Settings

| Setting          | Description                        |
| ---------------- | ---------------------------------- |
| Runtime          | Flink 1.15 or above                |
| Input Format     | JSON, Avro, CSV, etc.              |
| Scaling Mode     | Auto or Parallelism (manual)       |
| Monitoring       | CloudWatch, Application Logs       |
| Failure Handling | Flink’s checkpointing and recovery |

---

## ⚡ Why Choose MSF?

| Feature              | Amazon MSF ✅        | Self-Managed Flink ❌ |
| -------------------- | -------------------- | --------------------- |
| Serverless           | ✅ Yes               | ❌ You manage it      |
| Autoscaling          | ✅ Built-in          | ❌ Manual config      |
| HA and Resilience    | ✅ Built-in          | ❌ Setup Zookeeper/HA |
| Easy AWS Integration | ✅ Native Connectors | ⚠️ Requires setup     |

---

## 🎯 Real-Time Use Cases

- 🧾 Clickstream analytics
- 🛒 E-commerce orders + alerts
- 📈 Financial fraud detection
- ⚠️ IoT sensor monitoring
- 📡 Log transformation and delivery

---

## 💡 Pro Tip: SQL or Code?

Flink on MSF supports both:

- **Streaming SQL**: Quick, declarative processing
- **Java/Scala**: Advanced logic and pipelines

---

## ✅ Try It Yourself

👉 [Official Workshop: flink-on-msf](https://catalog.workshops.aws/managed-flink/en-US/flink-on-msf)
