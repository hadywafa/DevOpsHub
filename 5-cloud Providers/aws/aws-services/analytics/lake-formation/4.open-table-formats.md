# 📂 Open Table Format in Data Lakes: A Beginner’s Guide to Apache Iceberg, Delta Lake, and Apache Hudi

---

## 🧠 What’s the Problem We’re Solving?

Data lakes are amazing. They allow us to store petabytes of structured, semi-structured, and unstructured data at low cost using services like Amazon S3. But here’s the catch:

> “Object storage like S3 is **not a database**.”

That means:

- No ACID transactions (your data lake can’t guarantee atomic operations).
- No efficient updates or deletes (you can't modify a single record easily).
- No indexes (slow reads as your data grows).
- Schema evolution is tricky.
- And no "time travel" to go back to previous data versions.

### 🚨 So we need something _smarter_ than just files

Enter the superheroes: **Open Table Formats (OTFs)** 💪

---

## 🧩 What Is an Open Table Format?

An **Open Table Format** is a **layer on top of your data lake** (like S3) that gives your data some “database superpowers”:

| Capability                        | What It Means                        |
| --------------------------------- | ------------------------------------ |
| 🔁 ACID Transactions              | Guarantees all-or-nothing operations |
| 🔄 Record-level Updates & Deletes | Modify only what’s needed            |
| 🧭 Time Travel                    | Query past versions of your data     |
| 🧬 Schema Evolution               | Add/modify columns easily            |
| 🧠 Indexing & Partitioning        | Faster queries                       |
| 🔐 Governance & Lineage           | Audit who did what and when          |

---

## 🎓 Why Should You Care?

Let’s say your company has:

- CDC data (Change Data Capture from RDS)
- GDPR obligations to delete customer records
- Machine Learning pipelines
- Dashboard queries from Athena

Your standard Parquet + S3 approach won’t cut it. You need an **open table format**.

---

## 📚 Popular Open Table Formats

| Format            | Project          | Supported By        | Storage Format      |
| ----------------- | ---------------- | ------------------- | ------------------- |
| 🧊 Apache Iceberg | Apache           | Netflix, AWS, Apple | Parquet, ORC, Avro  |
| 🔺 Delta Lake     | Linux Foundation | Databricks, AWS     | Parquet             |
| 👕 Apache Hudi    | Apache           | Uber, AWS           | Parquet, ORC, HFile |

---

## 🧱 How Do Open Table Formats Work?

```mermaid
graph TD
  A[Data Files in S3] --> B[Open Table Format]
  B --> C[Metadata Layer (Manifests, Logs)]
  C --> D[Query Engines like Spark, Athena, EMR]
  C --> E[Write Engines like Glue, Flink]
```

Your data is still files (Parquet, ORC, etc.), but:

- A **metadata layer** tracks versions, partitions, schema, and indexes.
- Writers/Readers (e.g., Athena, EMR, Glue) access the data using this layer.

---

## 🧮 Key Features Compared

| Feature                | Apache Hudi        | Apache Iceberg        | Delta Lake             |
| ---------------------- | ------------------ | --------------------- | ---------------------- |
| ✅ ACID                | Yes                | Yes                   | Yes                    |
| 🔁 Time Travel         | Yes                | Yes                   | Yes                    |
| 📥 Streaming Ingestion | Best               | Good                  | Good                   |
| 🔄 Upserts             | Fast with indexes  | MERGE (slower)        | MERGE (slower)         |
| 🧠 Schema Evolution    | Yes                | Best (also partition) | Yes                    |
| 🧹 Auto Compaction     | Yes                | Manual                | Manual                 |
| 🧪 Time/Change Queries | Incremental        | Changelog views       | CDF (Change Data Feed) |
| 🧰 Tooling             | DeltaStreamer, CLI | CLI                   | Spark only             |

---

## 🧬 Real-World Examples & Use Cases

| Use Case                          | Format Recommendation          | Why                               |
| --------------------------------- | ------------------------------ | --------------------------------- |
| ✅ **Streaming with Upserts**     | Apache Hudi                    | Indexes + async compaction        |
| ✅ **Batch Updates**              | All (Hudi for advanced tuning) | All support COW (Copy On Write)   |
| ✅ **GDPR Deletes**               | All (Hudi best with cleaner)   | All support hard deletes          |
| ✅ **Time Travel for Analytics**  | All                            | Query older versions              |
| ✅ **Real-Time Dashboards**       | Iceberg or Hudi                | Low-latency queries               |
| ✅ **Schema Evolution Over Time** | Iceberg                        | Best schema & partition evolution |

---

## 🔗 AWS Services That Support Open Table Formats

| AWS Service              | Hudi          | Iceberg         | Delta          |
| ------------------------ | ------------- | --------------- | -------------- |
| Amazon EMR               | ✅ Read/Write | ✅              | ✅             |
| AWS Glue                 | ✅            | ✅              | ✅             |
| Amazon Athena            | ✅ (Read)     | ✅ (Read/Write) | ✅ (Read-only) |
| Amazon Redshift Spectrum | ✅            | ✅              | ✅ (Limited)   |
| Lake Formation           | ✅            | ✅              | ✅             |

📌 Glue Catalog supports all three formats.

---

## 🛠️ Common Challenges with Open Table Formats

| Challenge               | Explanation                                               |
| ----------------------- | --------------------------------------------------------- |
| ❌ Too Many Small Files | Caused by streaming ingestion; solved with **compaction** |
| ❌ No Native CDC        | Iceberg and Delta require preprocessing CDC records       |
| ❌ Maintenance Overhead | Iceberg and Delta require external compaction jobs        |
| ❌ Complexity           | More moving parts than flat Parquet files                 |

---

## 🚀 Recommendations

1. **Use Apache Hudi** for streaming + upserts + CDC (best for real-time).
2. **Use Iceberg** for schema evolution, Trino/Athena performance, and analytical workloads.
3. **Use Delta Lake** if you're already on Spark and need simple Copy-on-Write operations.

---

## 🧠 Final Thoughts

Open Table Formats are the backbone of modern **transactional data lakes**. They turn your cold S3 storage into something much smarter — capable of powering advanced analytics, real-time apps, and machine learning workloads without giving up governance and compliance.

---

## 🧰 Bonus Tip: Learn Hands-On

Try:

- ✅ Apache Hudi with DeltaStreamer on EMR
- ✅ Apache Iceberg with Athena (SQL support!)
- ✅ Delta Lake on AWS Glue Spark jobs

## 🔗 Reference

- [Choosing an open table format for your transactional data lake on AWS](https://aws.amazon.com/blogs/big-data/choosing-an-open-table-format-for-your-transactional-data-lake-on-aws/)

---

### 🧊 Apache Iceberg – Resources

#### 📘 Official Docs

- 🔗 [Apache Iceberg Documentation](https://iceberg.apache.org/docs/latest/)  
  Great for getting started with table format concepts, architecture, SQL commands, and integrations.

#### 📺 Videos

- 📹 [Apache Iceberg Introduction by Ryan Blue (Co-Creator)](https://www.youtube.com/watch?v=0XrRBEv5f2o) – A brilliant talk on the _why_ and _how_ of Iceberg.
- 📹 [Amazon Athena and Iceberg Deep Dive – AWS re:Invent](https://www.youtube.com/watch?v=NSFq5iOHxFY)

#### 📓 Hands-On Tutorials

- 🔧 [Iceberg on Amazon EMR](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/iceberg.html)
- 🧪 [Using Apache Iceberg with Athena](https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg.html)

#### 🧠 Blog Posts

- 🧾 [Netflix Engineering Blog: Iceberg at Scale](https://netflixtechblog.com/iceberg-a-new-table-format-for-huge-analytics-datasets-102e9fcbccfb)
- 🧾 [AWS Big Data Blog: Iceberg Performance Tips](https://aws.amazon.com/blogs/big-data/)

---

### 👕 Apache Hudi – Resources

#### 📘 Official Docs

- 🔗 [Apache Hudi Documentation](https://hudi.apache.org/docs/overview/)  
  Covers architecture, COW/MOR modes, DeltaStreamer, and integration guides.

#### 📺 Videos

- 📹 [Intro to Apache Hudi – Uber Engineering](https://www.youtube.com/watch?v=F_FO2v2Oh4g)
- 📹 [AWS re:Invent – Hudi on AWS with DeltaStreamer](https://www.youtube.com/watch?v=Owq52qJxz9Y)

#### 📓 Hands-On Tutorials

- 🧪 [Apache Hudi on Amazon EMR](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/hudi.html)
- 🧪 [CDC with Apache Hudi and AWS DMS](https://aws.amazon.com/blogs/big-data/ingest-and-update-data-in-data-lake-using-aws-dms-and-apache-hudi-on-amazon-emr/)

#### 🧠 Blog Posts

- 🧾 [Apache Hudi Deep Dive – AWS Blog](https://aws.amazon.com/blogs/big-data/apache-hudi-on-aws-part-1-overview/)
- 🧾 [How Uber Built Hudi](https://eng.uber.com/hudi/)

---

### 🔺 Delta Lake – Resources

#### 📘 Official Docs

- 🔗 [Delta Lake Documentation](https://docs.delta.io/latest/index.html)  
  Includes Python/Spark APIs, schema evolution, time travel, and performance tuning.

#### 📺 Videos

- 📹 [Intro to Delta Lake (Databricks)](https://www.youtube.com/watch?v=evhB9YFn1Tg)
- 📹 [Delta Lake on AWS Glue (re:Invent)](https://www.youtube.com/watch?v=9cT5ST38Fek)

#### 📓 Hands-On Tutorials

- 🧪 [Delta Lake on AWS Glue](https://docs.aws.amazon.com/glue/latest/dg/update-delta-lake.html)
- 🧪 [Getting Started with Delta Lake (on Databricks or EMR)](https://delta.io/getting-started/)

#### 🧠 Blog Posts

- 🧾 [Delta Lake Architecture](https://databricks.com/blog/2019/08/14/introducing-delta-lake-open-source-storage-layer.html)
- 🧾 [CDC with Delta Lake on AWS](https://aws.amazon.com/blogs/big-data/building-a-data-lakehouse-using-delta-lake-on-aws/)

---

### 📦 Comparison Articles & General Guides

- 📚 [AWS Blog: Choosing an Open Table Format (Hudi vs. Iceberg vs. Delta)](https://aws.amazon.com/blogs/big-data/building-open-table-format-data-lakes-on-aws/)
- 📚 [Onehouse Blog: Hudi vs Iceberg vs Delta](https://onehouse.ai/blog/hudi-vs-iceberg-vs-delta)
- 📚 [Databricks Comparison Chart](https://databricks.com/blog/2020/05/27/comparing-open-source-data-lakehouse-table-formats-apache-iceberg-apache-hudi-and-delta-lake.html)

---

### 🧪 Playground Environments

- 🧰 **Amazon EMR Notebooks** – Use Jupyter on EMR to try all three formats
- 🔁 **Docker with MinIO + Spark + Hive** – Emulate an S3-compatible lake on your laptop
