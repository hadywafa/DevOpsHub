# ğŸ§ª **AWS Glue DataBrew**

**Data cleaning is 80% of the job in data science. Why not make it easy?**

AWS Glue DataBrew is a **no-code, visual data preparation tool** that helps data analysts and scientists **clean, transform, and normalize data** for analytics & ML. Think of it as **Excel on steroids** with 250+ pre-built transformations!

---

[ğŸ”— Official Document So Awesome!](https://catalog.us-east-1.prod.workshops.aws/workshops/6532bf37-3ad2-4844-bd26-d775a31ce1fa/en-US/10-introduction)

<div style="text-align: center">
  <img src="images/glue-data-brew.png" alt="glue-data-brew" />
</div>

---

## ğŸ† **1. What is AWS Glue DataBrew?**

AWS Glue DataBrew is a **visual data preparation tool** that allows users to **clean and transform data** using a **spreadsheet-like UI** with **point-and-click** interactionsâ€”**no coding required!**

ğŸ”¹ **Key Features:**

- âœ… **Visual data transformation** (no-code approach)
- âœ… **250+ built-in transformations** (normalize, filter, split, aggregate, etc.)
- âœ… **Supports S3, RDS, Glue Catalog, Redshift, Snowflake, and more**
- âœ… **Creates â€œrecipesâ€ for repeatable transformations**
- âœ… **Integrates with AWS Glue ETL for automated processing**
- âœ… **Tracks data lineage** (visual workflow tracking)
- âœ… **Data profiling** for quality analysis

---

## ğŸ¯ **2. Why Use DataBrew? Who Should Use It?**

### ğŸ” **Why DataBrew?**

Most data analysts spend **80% of their time** cleaning and preparing data before they can analyze it.  
Instead of writing **SQL or Python scripts**, DataBrew **automates** this process with an **interactive UI**.

### ğŸ‘¨â€ğŸ’» **Who Should Use It?**

- âœ… **Data Analysts** â†’ Prepping reports, normalizing data
- âœ… **Data Scientists** â†’ Cleaning ML training datasets
- âœ… **BI & Business Teams** â†’ Quick ad-hoc data transformations
- âœ… **ETL Engineers** â†’ Automating cleaning before loading data

**ğŸ’¡ If you need to clean data but donâ€™t want to write Python or SQL, AWS Glue DataBrew is for you!**

---

## ğŸ”‘ **3. Core Concepts in DataBrew**

| ğŸ·ï¸ **Term**      | ğŸ“Œ **Definition**                                                       |
| ---------------- | ----------------------------------------------------------------------- |
| **Project**      | The entire workspace where you perform data preparation tasks.          |
| **Dataset**      | The structured or semi-structured data source (S3, RDS, JDBC, etc.).    |
| **Recipe**       | A series of transformation steps applied to a dataset.                  |
| **Job**          | Runs a recipe or data profiling task on a dataset.                      |
| **Data Lineage** | Tracks changes and transformations applied to data.                     |
| **Data Profile** | A summary of data quality (nulls, distributions, missing values, etc.). |

ğŸ›  **Example:**  
A data analyst wants to clean customer data before loading it into Redshift:

- âœ… **Dataset:** CSV file in S3
- âœ… **Project:** "Customer Cleanup"
- âœ… **Recipe:** Convert dates, remove duplicates, split names
- âœ… **Job:** Run the recipe & save output to S3

---

## âš™ï¸ **4. How AWS Glue DataBrew Works**

**Step-by-step DataBrew process:**

<div style="text-align: center">

```mermaid
graph TD;
    A[Dataset - CSV, RDS, Glue Catalog] -->|Load Data| B[Create Project]
    B -->|Apply Transformations| C[Define Recipe]
    C -->|Run Transformations| D[Create Job]
    D -->|Store Cleaned Data| E[S3, Redshift, Snowflake]
    E -->|Use for BI/ML| F[Tableau, Athena, QuickSight, SageMaker]
```

</div>

---

## ğŸš€ **5. Hands-on Example: Cleaning CitiBike Data**

### **Scenario:**

- ğŸ“Œ You are analyzing **CitiBike trip data** (New York bike rentals) from S3.
- ğŸ“Œ The dataset has **dirty data** (special characters, inconsistent date formats).
- ğŸ“Œ You want to **clean & prepare it for analysis**.

### **Step 1: Load Data into DataBrew**

- 1ï¸âƒ£ **Go to AWS Glue DataBrew Console**
- 2ï¸âƒ£ Click **Create Dataset** â†’ Choose **S3**
- 3ï¸âƒ£ Select **CitiBike.csv** file â†’ Click **Create Dataset**

### **Step 2: Create a DataBrew Project**

- 1ï¸âƒ£ Click **Create Project** â†’ Name it **"CitiBike Cleanup"**
- 2ï¸âƒ£ Select the **CitiBike Dataset**
- 3ï¸âƒ£ Click **Create**

### **Step 3: Apply Transformations (Create a Recipe)**

- âœ… **Convert timestamp to string**
- âœ… **Split date and time into separate columns**
- âœ… **Remove special characters from station names**
- âœ… **Filter out trips with missing values**
- âœ… **Group by month & count total trips**

**All actions are recorded as steps in a "Recipe"!**

### **Step 4: Run the Job & Export Clean Data**

- 1ï¸âƒ£ Click **Create Job** â†’ Choose **Recipe Job**
- 2ï¸âƒ£ Select **S3 as Output**
- 3ï¸âƒ£ Choose format **CSV or Parquet**
- 4ï¸âƒ£ Click **Run Job** ğŸ‰

---

## âš¡ **6. DataBrew vs AWS Glue ETL: Whatâ€™s the Difference?**

| Feature                 | AWS Glue DataBrew ğŸ§ª                  | AWS Glue ETL ğŸš€                |
| ----------------------- | ------------------------------------- | ------------------------------ |
| **Purpose**             | Visual data preparation               | Large-scale ETL processing     |
| **User Type**           | Data analysts, BI teams               | Data engineers, ETL developers |
| **Code Required?**      | âŒ No coding needed                   | âœ… Requires Python/Scala/Spark |
| **Use Case**            | Cleaning, transforming small datasets | Complex, large-scale ETL jobs  |
| **Output Destinations** | S3, Redshift, Glue Catalog            | S3, Redshift, DynamoDB, Athena |

> ğŸ’¡ **Use DataBrew when you need quick, no-code transformations**.  
> ğŸ’¡ **Use AWS Glue ETL when handling large-scale transformations with Spark**.

---

## ğŸ“Œ **7. Summary: Why AWS Glue DataBrew is a Game Changer**

- âœ… **No-code data preparation** for BI & ML
- âœ… **250+ built-in transformations** (filter, split, join, normalize, etc.)
- âœ… **Supports multiple data sources** (S3, RDS, Glue Catalog, Redshift, etc.)
- âœ… **Easy automation with recipes & jobs**
- âœ… **Perfect for data analysts & scientists**
