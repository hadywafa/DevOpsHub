# ğŸš€ **Amazon Kinesis Data Streams (KDS) - Real-Time Streaming Storage**

<div style="text-align: center;">
    <img src="images/aws-kds-in-data-pipeline.png" alt="aws-kds-in-data-pipeline" />
</div>

## ğŸ” **What is Kinesis Data Streams (KDS)?**

Amazon Kinesis Data Streams (KDS) is a fully managed AWS service that enables **real-time storage and delivery** of streaming data.  
It acts as a **high-speed message hub** where **producers send data, KDS temporarily stores it, and consumers process it**.

ğŸ’¡ **KDS is NOT a processing engine**â€”it simply stores and delivers data to consumers for further analysis.

ğŸ”¹ **Why Use Amazon Kinesis Data Streams?**

- âœ” **Real-time ingestion & delivery** - Stores streaming data within milliseconds.
- âœ” **Highly scalable & durable** - Can handle terabytes per hour.
- âœ” **Multiple consumers** - Several applications can read from the same stream.
- âœ” **Custom processing** - Consumers (like AWS Lambda, Apache Flink, or Spark) analyze the data.

ğŸ”¹ **Example Use Case:**

A financial trading system sends **stock market updates** to KDS.

- âœ” KDS **stores the data** in real-time.
- âœ” Consumers (Apache Flink) **analyze stock patterns**.
- âœ” Processed data is **stored in S3** for reporting.

---

## ğŸ— **How KDS Works**

- 1ï¸âƒ£ **Producers** put data into KDS (e.g., app logs, IoT data, stock prices).
- 2ï¸âƒ£ **KDS stores and delivers the data** (but does not process it).
- 3ï¸âƒ£ **Consumers (Lambda, Flink, Spark, etc.) process and analyze** the data.
- 4ï¸âƒ£ Processed data is **stored in destinations like S3, Redshift, or OpenSearch**.

---

<div style="text-align: center;">

```mermaid
graph LR
    A[ğŸš› **Producer** - Web Servers, IoT, Logs] -->|Puts Data| B[**Kinesis Data Stream** ğŸª - Stores Messages]
    B -->|Delivers Data| C[ğŸ” **Consumer** - Lambda, Flink, Spark]
    C -->|Stores & Analyzes Data| D[S3, Redshift, OpenSearch]
```

</div>

---

## ğŸ”‘ **Core Components of KDS**

<div style="text-align: center;">
    <img src="images/aws-kds-components.png" alt="aws-kds-components" />
</div>

---

### ğŸ— **1. Data Producers**

Producers send records to the **Kinesis Data Stream**. Examples:

- **Web apps & servers** - Send clickstream logs.
- **IoT devices** - Stream sensor data.
- **Stock market feeds** - Deliver price updates.

ğŸ‘‰ **AWS Services Used:**

- âœ” **Amazon Kinesis Producer Library (KPL)** - High-throughput producer API.
- âœ” **Amazon Kinesis Data Streams API** - Supports `PutRecord` & `PutRecords` methods.
- âœ” **Amazon Kinesis Agent** - Monitors and sends logs to KDS.

---

### ğŸ›  **2. Amazon Kinesis Data Streams (KDS)**

ğŸ’¡ **KDS is a real-time storage & delivery service, NOT a processing engine**.

- âœ” **Stores & delivers records** in milliseconds.
- âœ” Supports **multiple consumers** reading from the same stream.
- âœ” Scales automatically based on throughput needs.

**KDS Terminology**:

| Term                 | Description                                                      |
| -------------------- | ---------------------------------------------------------------- |
| **Record**           | A single unit of data sent by a producer (e.g., JSON, CSV).      |
| **Partition Key**    | Determines which shard a record is sent to.                      |
| **Shard**            | A unit of capacity within a stream that handles records.         |
| **Retention Period** | Stores data for **24 hours** (default) or **7 days** (extended). |

ğŸ”¹ **Example:**  
A streaming **weather monitoring system** sends temperature readings every second.

- âœ” KDS **stores the data**.
- âœ” Consumers **analyze** it in real-time for weather forecasts.

---

### ğŸ” **3. Data Consumers**

Consumers **retrieve and process data from KDS**. Examples:

- **AWS Lambda** - Serverless event processing.
- **Apache Flink** - Real-time stream analytics.
- **Amazon EMR / Spark** - Advanced transformations.

ğŸ‘‰ **AWS Services Used:**

- âœ” **Amazon Kinesis Client Library (KCL)** - Helps build Kinesis applications in Java, Python, etc.
- âœ” **AWS Lambda** - Event-driven processing.
- âœ” **Amazon Managed Service for Apache Flink** - Stream processing at scale.

---

## ğŸ“Š **Shards: The Building Blocks of KDS**

A **shard** is a unit of capacity that defines how much data a stream can handle.

âœ” **Each shard supports**:

- âœ… **Write capacity:** **1 MB/sec** or **1,000 records/sec**.
- âœ… **Read capacity:** **2 MB/sec** (max 5 transactions/sec).
- âœ… **Scaling:** Increase or decrease shards manually or with Auto-Scaling.

```mermaid
graph LR
    A[Data Producer ğŸš›] -->|Writes Data| B[Shard #1 ğŸ—ƒ]
    A -->|Writes Data| C[Shard #2 ğŸ—ƒ]
    A -->|Writes Data| D[Shard #3 ğŸ—ƒ]
    B -->|Reads Data| E[Consumer ğŸ”]
    C -->|Reads Data| E
    D -->|Reads Data| E
```

ğŸ‘‰ **Example:**  
A ride-hailing app **assigns trips** to different shards using a **Partition Key (City Name)**.

- âœ” **"New York" records go to Shard #1**
- âœ” **"Los Angeles" records go to Shard #2**

---

## ğŸš¨ **Handling Throttling & Scaling**

Throttling occurs when **shard limits are exceeded**, causing data loss.

ğŸš« **Causes of Throttling:**

- **Hot Shards:** Some shards get more traffic than others (uneven partition key distribution).
- **Not Enough Capacity:** Too few shards to handle the load.

âœ… **Solutions:**

- âœ” **Use balanced partition keys** to distribute records evenly.
- âœ” **Enable Auto-Scaling** to dynamically adjust shards.
- âœ” **Use On-Demand Mode** (AWS manages capacity for you).

---

## âš– **Capacity Modes**

| Mode            | Use Case                                    | Limits                            |
| --------------- | ------------------------------------------- | --------------------------------- |
| **On-Demand**   | Automatic scaling for unpredictable traffic | **200 MB/s write, 400 MB/s read** |
| **Provisioned** | Predictable workloads with controlled costs | No limit on throughput            |

ğŸ’¡ **When to Choose On-Demand Mode?**

- âœ” New streams with unknown traffic.
- âœ” Spiky workloads with unpredictable traffic.

ğŸ’¡ **When to Choose Provisioned Mode?**

- âœ” Workloads with steady, predictable traffic.
- âœ” Need control over shard count & costs.

---

## ğŸš€ **Kinesis Data Streams CLI Operations**

### ğŸ”¹ **1. Create a Stream**

```bash
aws kinesis create-stream --stream-name MyStream --shard-count 2
```

### ğŸ”¹ **2. Put a Record**

```bash
aws kinesis put-record --stream-name MyStream --partition-key "123" --data "Hello, Kinesis!"
```

### ğŸ”¹ **3. Retrieve Data**

1ï¸âƒ£ **Get Shard Iterator (starting position in the stream):**

```bash
aws kinesis get-shard-iterator --stream-name MyStream --shard-id "shardId-000000000000" --shard-iterator-type TRIM_HORIZON
```

2ï¸âƒ£ **Get Records from the Stream:**

```bash
aws kinesis get-records --shard-iterator <Shard Iterator>
```

---

## ğŸ¯ **Key Takeaways**

- âœ” **KDS is a real-time data storage and delivery system, NOT a processing engine.**
- âœ” **Producers send data â†’ KDS stores it â†’ Consumers process it.**
- âœ” **Shards define capacity & scalability** (1 MB/sec write, 2 MB/sec read per shard).
- âœ” **Auto-Scaling & On-Demand Mode help manage dynamic workloads.**
- âœ” **AWS CLI enables basic stream management.**
